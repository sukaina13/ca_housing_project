{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression (SVR) Model\n",
    "\n",
    "This notebook demonstrates the use of Support Vector Regression (SVR) for predicting California housing prices.  \n",
    "SVR is a kernel-based method that works well for capturing non-linear relationships while being robust to outliers.  \n",
    "\n",
    "Key strengths of SVR:\n",
    "- Handles **non-linear patterns** in data effectively (with RBF kernel).  \n",
    "- Robust to **outliers**, since only support vectors influence the model.  \n",
    "- Provides a balance between **model complexity** (controlled by `C`) and **error tolerance** (controlled by `epsilon`).  \n",
    "\n",
    "While SVR can be computationally expensive on large datasets, it provides a valuable comparison point to tree-based models (Decision Tree, Random Forest) by approaching regression from a completely different perspective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "We load the processed training dataset (24 features + target) from the `/data/train` directory.  \n",
    "Since the data is already preprocessed, we can directly use it for training the SVR model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed train shape: (16512, 24)\n"
     ]
    }
   ],
   "source": [
    "#importing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Paths\n",
    "PROJECT_DIR = Path(\"/Users/sukainaalkhalidy/Desktop/CMSE492/ca_housing_project\")\n",
    "TRAIN_PROCESSED_FP = PROJECT_DIR / \"data\" / \"train\" / \"housing_train_processed.csv\"\n",
    "MODEL_FP = PROJECT_DIR / \"models\" / \"svr_model.pkl\"\n",
    "\n",
    "# Load processed dataset\n",
    "housing = pd.read_csv(TRAIN_PROCESSED_FP)\n",
    "print(\"Processed train shape:\", housing.shape)\n",
    "\n",
    "X = housing.drop(\"median_house_value\", axis=1)\n",
    "y = housing[\"median_house_value\"]\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting\n",
    "\n",
    "We initialize and train a Support Vector Regression (SVR) model with default hyperparameters.  \n",
    "The training RMSE is reported as a baseline measure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 117845.90056517681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the SVR model\n",
    "# Using the Radial Basis Function (RBF) kernel to capture non-linear relationships\n",
    "svr_reg = SVR(kernel=\"rbf\")\n",
    "\n",
    "# Fit the model on the processed training data\n",
    "svr_reg.fit(X, y)\n",
    "\n",
    "# Generate predictions on the training set\n",
    "predictions = svr_reg.predict(X)\n",
    "\n",
    "# Evaluate performance using RMSE (Root Mean Squared Error)\n",
    "mse = mean_squared_error(y, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Training RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "\n",
    "We evaluate the SVR model using 3-fold cross-validation.  \n",
    "(SVR is computationally expensive, so we reduce folds for runtime.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores: [119264.7294137  118900.17351597 115424.15386263]\n",
      "Mean RMSE: 117863.01893076643\n",
      "Std deviation: 1730.9481729371757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Use the plain SVR model you trained earlier\n",
    "scores = cross_val_score(svr_reg, X, y,\n",
    "                         scoring=\"neg_mean_squared_error\",\n",
    "                         cv=3,\n",
    "                         n_jobs=1)\n",
    "\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(\"RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Std deviation:\", rmse_scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "We perform hyperparameter tuning on a reduced search space  \n",
    "to keep runtime manageable. GridSearchCV is used to search over `C` and `gamma`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Define small parameter grid\n",
    "param_grid = {\n",
    "    \"C\": [1, 10],\n",
    "    \"epsilon\": [0.1, 0.2],\n",
    "    \"gamma\": [\"scale\", 0.1],\n",
    "    \"kernel\": [\"rbf\"]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    SVR(),\n",
    "    param_grid,\n",
    "    cv=2,   # fewer folds for speed\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Use a subset (20% of data) for faster runtime\n",
    "X_small = X.sample(frac=0.2, random_state=42)\n",
    "y_small = y.loc[X_small.index]\n",
    "\n",
    "grid.fit(X_small, y_small)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "\n",
    "# Extract best model\n",
    "best_svr = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Saving\n",
    "\n",
    "We save the tuned SVR model to the `/models` directory  \n",
    "so it can be reused later without retraining.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /Users/sukainaalkhalidy/Desktop/CMSE492/ca_housing_project/models/svr_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Define absolute project directory (adjust if needed)\n",
    "PROJECT_DIR = Path(\"/Users/sukainaalkhalidy/Desktop/CMSE492/ca_housing_project\")\n",
    "MODELS_DIR = PROJECT_DIR / \"models\"\n",
    "\n",
    "# Ensure the /models directory exists\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_FP = MODELS_DIR / \"svr_model.pkl\"\n",
    "\n",
    "# Save tuned model if available, else fallback to default\n",
    "model_to_save = best_svr if \"best_svr\" in globals() else svr_reg\n",
    "joblib.dump(model_to_save, MODEL_FP)\n",
    "\n",
    "print(f\"Model saved to {MODEL_FP}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
